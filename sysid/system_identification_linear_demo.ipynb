{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a tutorial based on the following manuscript: \n",
    "\n",
    "[INVERSE BOUNDARY VALUE AND OPTIMAL CONTROL PROBLEMS ON\n",
    "GRAPHS: A NEURAL AND NUMERICAL SYNTHESIS](https://arxiv.org/pdf/2206.02911). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial Differential Equations (PDEs) are among the most studied mathematical models, representing many systems in science and engineering. A PDE describes the time evolution of a dynamical system defined over a spatial region.\n",
    "PDEs and machine learning (ML) can mutually enhance each other. ML can be used to learn solutions to PDEs or to infer PDEs in inverse problems, while PDEs can inspire the design of ML algorithms.\n",
    "\n",
    "As an example of the first case, where ML aids in solving PDEs, consider physics-informed neural networks (PINNs), which have gained significant attention in recent years. The idea behind PINNs is to integrate physical knowledge in the form of PDEs into the learning algorithm. The neural network models the solution of the PDE, and with automatic differentiation, the network is tuned to fit the data while adhering to the physical laws. After training, a PINN can generate solutions to a PDE given the initial and boundary conditions, eliminating the need for numerical simulation techniques like the finite element method. Our work is similar to PINNs in that we aim to learn the differential equation that generated the observational data. However, our approach differs because we do not assume prior knowledge of the form of the PDE, making it applicable in more general settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/vonKarman.png\" width=500>\n",
    "\n",
    "A cylinder is obstructing a flow and creating vortices as a result. This type of fluid dynamics can be modelled as a PDE. <a href=\"https://en.wikipedia.org/wiki/K%C3%A1rm%C3%A1n_vortex_street\">Image source</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of how PDEs can inspire novel ML algorithms is the diffusion equation, which models information propagation over a topological space. The diffusion equation is a well-known PDE that describes the diffusion of fields such as energy, mass concentration, or information over a medium. It has been shown that the dynamics of graph neural networks (GNNs) can be interpreted as the numerical integration of the diffusion equation over a discretized space. GNNs are neural networks that compute the updated state of nodes in a graph based on their neighboring nodes, with message passing implemented over the edges. The underlying graph of a GNN is analogous to the discretization schemes used in numerical solutions of PDEs. This natural connection between GNNs and PDEs makes GNNs strong candidates for modeling the updates of dynamical systems described by unknown PDEs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamical systems are ubiquitous in nature and industral applications alike. Here are a short list of possible applications:\n",
    "\n",
    "- Optimal resource allocation in networks\n",
    "- Traffic flow and congestion models\n",
    "- Brain computer interfaces\n",
    "- Crowd dynamics in urban planning\n",
    "- Heat transfer in industrial processes\n",
    "- Water resource management\n",
    "- Pollution dispersion\n",
    "- Customer behavior modelling in markeing\n",
    "- Pricing strategies\n",
    "- Mean field game theory\n",
    "- Option pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our explicit goal is: using graph neural networks to learn a dyanmical system on a graph with boundary. This is done through a model called _Boundary Informed Graph Neural ODE_, or for short, **BigNode**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our method learns to represent the unknown PDE that generated the observations over space and time, treating it as a system of ODEs at each point in space. We model the observational data as the numerical integration of a GNN over an underlying graph, which is a discretization of the spatial domain. The main innovation of our approach lies in handling the known boundary conditions of the system. Unlike the standard PINN approach, which imposes boundary conditions as a penalty term in the loss function, our method addresses them in a structured way, similar to how boundary conditions are handled in numerical PDE solutions. We use the underlying graph with boundary nodes and directly enforce the boundary conditions through boundary-injected message passing layers of the GNN. Finally, the integration and backpropagation of the GNN over time are performed using the framework of Neural ODEs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from bignode_no_ctrl import BIGNODE\n",
    "from utils_sysid import train, inference, compute_RMSE\n",
    "from utils_visualization import visualize_state_sysid\n",
    "from utils import experiment_init\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_DIR = \"data/linear\"\n",
    "\n",
    "# Load graph data\n",
    "with open(os.path.join(ROOT_DIR, DATA_DIR, \"graph_obj.pickle\"), \"rb\") as handle:\n",
    "    graph_obj = pickle.load(handle)\n",
    "num_nodes_int = graph_obj[\"num_nodes_int\"]\n",
    "num_nodes_bound = graph_obj[\"num_nodes_bound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphs are represented in the following format which is friendly to Torch. \n",
    "graph_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![](../imgs/bignode_img1.png) -->\n",
    "<img src=\"../imgs/bignode_img1.png\" width=500>\n",
    "<!-- from IPython.display import Image, display\n",
    "display(Image(filename=\"/Users/boofebeena/Pictures/Plots/bignode_img1.png\")) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NEED CLEAR PROBLEM STATEMENT AS TO WHAT'S UP WITH BOUNDARY NODES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load system data\n",
    "with open(os.path.join(ROOT_DIR, DATA_DIR, \"system_data.pickle\"), \"rb\") as handle:\n",
    "    system_data = pickle.load(handle)\n",
    "\n",
    "print(system_data.keys())\n",
    "print(system_data['system_name']) # We're working with synthetic head diffusion data\n",
    "print(system_data['timestamps'].shape) # 1001 timestamps\n",
    "print(system_data['U']) # U denotes control nodes, empty in this example\n",
    "print(system_data['X_int'].shape) # Observations on graph interior with 10 gray nodes\n",
    "print(system_data['X_bound'].shape) # Two boundary nodes in cyan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data comes from a numerical simulation of the standard diffusion formula:\n",
    "\n",
    "$\\dot{\\bf{x}} = - \\kappa \\Delta \\bf{x}$\n",
    "\n",
    "where $\\kappa$ is a diffusitivity coefficient, and $\\Delta = \\mathrm{grad}^*\\mathrm{grad} = - \\mathrm{div}\\, \\mathrm{grad}$ is the standard Laplacian. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_TYPE = \"linear\"\n",
    "MESSAGE_DIM = 32\n",
    "EMBED_DIM = 32\n",
    "REGULARIZATION = True\n",
    "EXPERIMENT_NAME = \"bignode_reg_linear\" if REGULARIZATION else \"bignode_linear\"\n",
    "EPOCHS = 2000\n",
    "\n",
    "random.seed(23)\n",
    "np.random.seed(23)\n",
    "torch.manual_seed(23)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.cuda.manual_seed_all(23)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "bignode = BIGNODE(input_dim=1, message_dim=MESSAGE_DIM, embed_dim=EMBED_DIM, bvp_type=\"dirichlet\",\n",
    "                    num_nodes_int=num_nodes_int, num_nodes_bound=num_nodes_bound, device=device)\n",
    "\n",
    "# Initializing the experiment\n",
    "experiment_dirs = experiment_init(experiment_name=EXPERIMENT_NAME, graph_obj=graph_obj, system_data=system_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NEED A VISUAL FOR MODEL ARCHITECTURE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BOUNDARY INJECTION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model, losses = train(graph_obj=graph_obj,\n",
    "                system_data=system_data,\n",
    "                regularization=REGULARIZATION,\n",
    "                model=bignode,\n",
    "                model_dir=experiment_dirs[\"model_dir\"],\n",
    "                epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Train loss convergence')\n",
    "plt.plot(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dirs[\"visualization_dir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training evaluation\n",
    "X_int_hat = inference(graph_obj, system_data, model)\n",
    "visualize_state_sysid(system_type=SYSTEM_TYPE,\n",
    "                        graph_obj=graph_obj,\n",
    "                        X_bound=system_data[\"X_bound\"],\n",
    "                        X_int=system_data[\"X_int\"],\n",
    "                        X_int_hat=X_int_hat,\n",
    "                        visualization_dir=experiment_dirs[\"visualization_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NEED MODEL CONVERGENCE PLOT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_plots_dir = os.path.join(ROOT_DIR, 'artifacts/bignode_reg_linear_2024-11-09-16-06-24/visualization/')\n",
    "node_plots = os.listdir(art_plots_dir)\n",
    "\n",
    "for filename in node_plots:\n",
    "    display(Image(filename=os.path.join(art_plots_dir, filename), width=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NONLINEAR CASE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_TYPE = \"nonlinear\"\n",
    "DATA_DIR = \"data/nonlinear\"\n",
    "\n",
    "# Load graph data\n",
    "with open(os.path.join(ROOT_DIR, DATA_DIR, \"graph_obj.pickle\"), \"rb\") as handle:\n",
    "    graph_obj = pickle.load(handle)\n",
    "num_nodes_int = graph_obj[\"num_nodes_int\"]\n",
    "num_nodes_bound = graph_obj[\"num_nodes_bound\"]\n",
    "\n",
    "# Load system data\n",
    "with open(os.path.join(ROOT_DIR, DATA_DIR, \"system_data.pickle\"), \"rb\") as handle:\n",
    "    system_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSAGE_DIM = 64\n",
    "EMBED_DIM = 64\n",
    "REGULARIZATION = True\n",
    "EXPERIMENT_NAME = \"bignode_reg_nonlinear\" if REGULARIZATION else \"bignode_nonlinear\"\n",
    "\n",
    "# Initializing the model\n",
    "bignode = BIGNODE(input_dim=1, message_dim=MESSAGE_DIM, embed_dim=EMBED_DIM, bvp_type=\"dirichlet\",\n",
    "                    num_nodes_int=num_nodes_int, num_nodes_bound=num_nodes_bound, device=device)\n",
    "\n",
    "# Initializing the experiment\n",
    "experiment_dirs = experiment_init(experiment_name=EXPERIMENT_NAME, graph_obj=graph_obj, system_data=system_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model, losses = train(graph_obj=graph_obj,\n",
    "                system_data=system_data,\n",
    "                regularization=REGULARIZATION,\n",
    "                model=bignode,\n",
    "                model_dir=experiment_dirs[\"model_dir\"],\n",
    "                epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Train loss convergence')\n",
    "plt.plot(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_plots_dir = os.path.join(ROOT_DIR, 'artifacts/bignode_reg_nonlinear_2024-11-10-16-31-59/visualization/')\n",
    "node_plots = os.listdir(art_plots_dir)\n",
    "\n",
    "for filename in node_plots:\n",
    "    display(Image(filename=os.path.join(art_plots_dir, filename), width=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[REGULARIZATION]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [NEED CONCLUSION AN COMMENTARY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/lin.png\" width=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/lin.png\" width=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
